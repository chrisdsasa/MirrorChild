import SwiftUI
import Speech
import Combine

struct VoiceCaptureView: View {
    @StateObject private var voiceCaptureManager = VoiceCaptureManager.shared
    @State private var showingPermissionAlert = false
    @State private var alertMessage = ""
    @State private var showingSettingsAlert = false
    @State private var isBlinking = false
    @Environment(\.dismiss) private var dismiss
    @Environment(\.scenePhase) private var scenePhase
    
    // å­˜å‚¨APIå“åº”æ–‡æœ¬
    @State private var apiResponseText = ""
    // è·Ÿè¸ªé¡µé¢çŠ¶æ€
    @State private var hasAppeared = false
    @State private var stateResetter: AnyCancellable?
    
    // Check if running in preview mode
    private var isRunningInPreview: Bool {
        ProcessInfo.processInfo.environment["XCODE_RUNNING_FOR_PREVIEWS"] == "1"
    }
    
    var body: some View {
        ZStack {
            // Background with subtle gradient
            LinearGradient(
                gradient: Gradient(colors: [
                    Color(red: 0.97, green: 0.97, blue: 0.98),
                    Color(red: 0.96, green: 0.96, blue: 0.98),
                    Color(red: 0.95, green: 0.95, blue: 0.98)
                ]),
                startPoint: .top,
                endPoint: .bottom
            ).ignoresSafeArea()
            
            // Cherry blossom decorative elements (subtle)
            GeometryReader { geometry in
                ZStack {
                    // Top right cherry blossom
                    Image(systemName: "leaf.fill")
                        .font(.system(size: 24))
                        .foregroundColor(Color.pink.opacity(0.2))
                        .position(x: geometry.size.width - 40, y: 60)
                    
                    // Bottom left cherry blossom
                    Image(systemName: "leaf.fill")
                        .font(.system(size: 20))
                        .foregroundColor(Color.pink.opacity(0.15))
                        .position(x: 30, y: geometry.size.height - 100)
                }
            }
            
            VStack(spacing: 15) {
                // Title with elegant, minimalist design
                HStack {
                    Spacer()
                    Text("voiceProfileTitle".localized)
                        .font(.appFont(size: 24, weight: .black))
                        .tracking(1)
                        .foregroundColor(Color(red: 0.3, green: 0.3, blue: 0.35))
                    Spacer()
                }
                .padding(.top, 20)
                .padding(.horizontal)
                
                // Status indicator
                HStack {
                    Circle()
                        .fill(voiceCaptureManager.isRecording ? 
                              Color(red: 0.2, green: 0.8, blue: 0.2) : Color(red: 0.8, green: 0.4, blue: 0.4))
                        .frame(width: 12, height: 12)
                        .opacity(voiceCaptureManager.isRecording ? (isBlinking ? 1.0 : 0.5) : 1.0)
                    
                    Text(voiceCaptureManager.isRecording ? 
                         "listeningMessage".localized : "voiceOffMessage".localized)
                        .font(.system(size: 16, weight: .medium))
                        .foregroundColor(Color(red: 0.4, green: 0.4, blue: 0.45))
                }
                .padding(.vertical, 10)
                .padding(.horizontal, 20)
                .background(
                    RoundedRectangle(cornerRadius: 20)
                        .fill(Color.white.opacity(0.9))
                        .shadow(color: Color.black.opacity(0.05), radius: 2, x: 0, y: 1)
                )
                
                // åˆ†éš”è§†å›¾ä¸ºä¸¤ä¸ªéƒ¨åˆ†
                GeometryReader { geo in
                    VStack(spacing: 15) {
                        // ç”¨æˆ·è¯­éŸ³è½¬å†™åŒºåŸŸ - ä¸ŠåŠéƒ¨åˆ†
                        VStack {
                            Text("æ‚¨çš„è¯­éŸ³")
                                .font(.system(size: 16, weight: .medium))
                                .foregroundColor(Color(red: 0.4, green: 0.4, blue: 0.5))
                                .frame(maxWidth: .infinity, alignment: .leading)
                                .padding(.horizontal)
                                .padding(.top, 8)
                            
                            if voiceCaptureManager.isRecording || !voiceCaptureManager.transcribedText.isEmpty {
                                transcriptionView
                                    .padding()
                                    .frame(height: max(100, geo.size.height / 2 - 40))
                            } else {
                                emptyStateView
                                    .frame(height: max(100, geo.size.height / 2 - 40))
                            }
                        }
                        .frame(maxWidth: .infinity)
                        .background(
                            RoundedRectangle(cornerRadius: 16)
                                .fill(Color.white.opacity(0.9))
                                .shadow(color: Color.black.opacity(0.05), radius: 5, x: 0, y: 2)
                                .overlay(
                                    RoundedRectangle(cornerRadius: 16)
                                        .stroke(Color(red: 0.7, green: 0.8, blue: 0.7).opacity(0.3), lineWidth: 1)
                                )
                        )
                        
                        // AIå“åº”åŒºåŸŸ - ä¸‹åŠéƒ¨åˆ†
                        VStack {
                            Text("AIåŠ©æ‰‹")
                                .font(.system(size: 16, weight: .medium))
                                .foregroundColor(Color(red: 0.4, green: 0.4, blue: 0.5))
                                .frame(maxWidth: .infinity, alignment: .leading)
                                .padding(.horizontal)
                                .padding(.top, 8)
                            
                            apiResponseView
                                .padding()
                                .frame(height: max(100, geo.size.height / 2 - 40))
                        }
                        .frame(maxWidth: .infinity)
                        .background(
                            RoundedRectangle(cornerRadius: 16)
                                .fill(Color.white.opacity(0.9))
                                .shadow(color: Color.black.opacity(0.05), radius: 5, x: 0, y: 2)
                                .overlay(
                                    RoundedRectangle(cornerRadius: 16)
                                        .stroke(Color(red: 0.7, green: 0.7, blue: 0.9).opacity(0.3), lineWidth: 1)
                                )
                        )
                    }
                    .padding(.horizontal, 20)
                }
                
                // Control buttons
                HStack(spacing: 60) {
                    if voiceCaptureManager.isRecording {
                        // Stop button
                        Button(action: stopRecording) {
                            Text("stopListening".localized)
                                .font(.system(size: 17, weight: .medium))
                                .foregroundColor(.white)
                                .padding(.vertical, 14)
                                .padding(.horizontal, 30)
                                .background(
                                    Capsule()
                                        .fill(Color(red: 0.8, green: 0.4, blue: 0.4))
                                )
                                .shadow(color: Color.black.opacity(0.1), radius: 3, x: 0, y: 2)
                        }
                    } else {
                        // Start button
                        Button(action: startRecording) {
                            Text("startListening".localized)
                                .font(.system(size: 17, weight: .medium))
                                .foregroundColor(.white)
                                .padding(.vertical, 14)
                                .padding(.horizontal, 30)
                                .background(
                                    Capsule()
                                        .fill(Color.accentColor)
                                )
                                .shadow(color: Color.black.opacity(0.1), radius: 3, x: 0, y: 2)
                        }
                    }
                }
                .padding(.top, 25)
                .padding(.bottom, 35)
                .padding(.horizontal, 30)
            }
        }
        .onAppear {
            if hasAppeared {
                print("ğŸ“± VoiceCaptureViewé‡æ–°å‡ºç°ï¼Œå¼ºåˆ¶é‡ç½®æœåŠ¡")
                resetService()
            }
            
            hasAppeared = true
            
            // æ£€æŸ¥éº¦å…‹é£æƒé™
            checkPermissions()
            
            // è®¾ç½®é—ªçƒæ•ˆæœåŠ¨ç”»
            withAnimation(Animation.easeInOut(duration: 0.8).repeatForever(autoreverses: true)) {
                isBlinking = true
            }
            
            // å®Œå…¨é‡ç½®OpenAIæœåŠ¡ï¼Œç¡®ä¿çŠ¶æ€å¹²å‡€
            resetService()
            
            // ç›‘å¬TTSæ’­æ”¾å®Œæˆé€šçŸ¥ï¼Œç¡®ä¿UIçŠ¶æ€æ­£ç¡®æ›´æ–°
            NotificationCenter.default.addObserver(forName: .didFinishPlayingTTS, object: nil, queue: .main) { _ in
                print("ğŸ“± VoiceCaptureViewæ”¶åˆ°TTSæ’­æ”¾å®Œæˆé€šçŸ¥")
                // å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ›´æ–°UIçŠ¶æ€
            }
            
            // æ·»åŠ ä¸€ä¸ªå®šæ—¶å™¨ï¼Œæ¯15ç§’æ£€æŸ¥å¹¶é‡ç½®æœåŠ¡çŠ¶æ€
            stateResetter = Timer.publish(every: 15, on: .main, in: .common)
                .autoconnect()
                .sink { _ in
                    print("ğŸ“± VoiceCaptureViewå®šæ—¶æ£€æŸ¥æœåŠ¡çŠ¶æ€")
                    if !voiceCaptureManager.isRecording {
                        // å¦‚æœæ²¡æœ‰å½•éŸ³ï¼Œé‡ç½®æœåŠ¡ï¼Œé¿å…çŠ¶æ€å¡ä½
                        OpenAIService.shared.reset()
                    }
                }
        }
        .onDisappear {
            print("ğŸ“± VoiceCaptureViewæ¶ˆå¤±")
            cleanupView()
        }
        .onChange(of: scenePhase) { oldPhase, newPhase in
            switch newPhase {
            case .background:
                print("ğŸ“± åº”ç”¨è¿›å…¥åå°")
                cleanupView()
            case .active:
                if hasAppeared {
                    print("ğŸ“± åº”ç”¨æ¢å¤å‰å°")
                    resetService()
                }
            default:
                break
            }
        }
        .alert(isPresented: $showingPermissionAlert) {
            if showingSettingsAlert {
                return Alert(
                    title: Text("permissionNeeded".localized),
                    message: Text(alertMessage),
                    primaryButton: .default(Text("openSettings".localized)) {
                        if let url = URL(string: UIApplication.openSettingsURLString) {
                            UIApplication.shared.open(url)
                        }
                    },
                    secondaryButton: .cancel(Text("cancel".localized))
                )
            } else {
                return Alert(
                    title: Text("permissionDenied".localized),
                    message: Text(alertMessage),
                    dismissButton: .default(Text("OK"))
                )
            }
        }
    }
    
    private var transcriptionView: some View {
        ScrollView {
            VStack(alignment: .leading, spacing: 10) {
                // èƒŒæ™¯å½•éŸ³æŒ‡ç¤ºå™¨
                if UIApplication.shared.applicationState == .background && voiceCaptureManager.isRecording {
                    Text("(åå°å½•éŸ³ä¸­...)")
                        .font(.system(size: 12, weight: .medium))
                        .foregroundColor(Color.orange)
                        .padding(.bottom, 5)
                }
                
                // Preview mode shows simulated text
                if isRunningInPreview && voiceCaptureManager.isRecording {
                    Text("This is simulated speech recognition text in preview mode. Actual speech-to-text content will be shown on real devices.")
                        .font(.system(size: 18, weight: .regular))
                        .foregroundColor(Color(red: 0.25, green: 0.25, blue: 0.3))
                        .lineSpacing(5)
                } else {
                    Text(voiceCaptureManager.transcribedText)
                        .font(.system(size: 18, weight: .regular))
                        .foregroundColor(Color(red: 0.25, green: 0.25, blue: 0.3))
                        .lineSpacing(5)
                }
            }
            .frame(maxWidth: .infinity, alignment: .leading)
            .padding()
        }
    }
    
    private var apiResponseView: some View {
        ScrollView {
            VStack(alignment: .leading, spacing: 10) {
                if apiResponseText.isEmpty {
                    Text("AIåŠ©æ‰‹å°†åœ¨æ‚¨è¯´è¯åå›åº”...")
                        .font(.system(size: 16, weight: .regular))
                        .foregroundColor(Color.gray)
                        .frame(maxWidth: .infinity, alignment: .center)
                        .padding(.vertical, 30)
                } else {
                    Text(apiResponseText)
                        .font(.system(size: 16, weight: .regular))
                        .foregroundColor(Color(red: 0.2, green: 0.2, blue: 0.3))
                        .lineSpacing(6)
                }
            }
            .frame(maxWidth: .infinity, alignment: .leading)
            .padding()
        }
    }
    
    private var emptyStateView: some View {
        VStack(spacing: 20) {
            Image(systemName: "waveform")
                .font(.system(size: 60))
                .foregroundColor(Color(red: 0.7, green: 0.8, blue: 0.7).opacity(0.5))
            
            if voiceCaptureManager.permissionStatus == .denied {
                Text("permissionDeniedMessage".localized)
                    .font(.system(size: 18, weight: .medium))
                    .foregroundColor(Color(red: 0.5, green: 0.5, blue: 0.6))
                    .multilineTextAlignment(.center)
                    .padding(.horizontal, 40)
            } else {
                Text("tapToStartListening".localized)
                    .font(.system(size: 18, weight: .medium))
                    .foregroundColor(Color(red: 0.5, green: 0.5, blue: 0.6))
                    .multilineTextAlignment(.center)
                    .padding(.horizontal, 40)
            }
        }
    }
    
    private func startRecording() {
        // Simplified behavior in preview mode
        if isRunningInPreview {
            voiceCaptureManager.isRecording = true
            voiceCaptureManager.transcribedText = "This is simulated recording text in preview mode. On real devices, this would show actual speech recognition results."
            return
        }
        
        // Request permissions when user taps the button
        voiceCaptureManager.startRecording { success, error in
            if !success, let error = error {
                self.alertMessage = error.localizedDescription
                self.showingPermissionAlert = true
            }
        }
    }
    
    private func stopRecording() {
        if isRunningInPreview {
            voiceCaptureManager.isRecording = false
            return
        }
        
        voiceCaptureManager.stopRecording()
    }
    
    private func checkPermissions() {
        voiceCaptureManager.checkPermissionStatus()
        
        if voiceCaptureManager.permissionStatus == .denied {
            alertMessage = "éœ€è¦éº¦å…‹é£è®¿é—®æƒé™æ‰èƒ½ä½¿ç”¨è¯­éŸ³åŠŸèƒ½ã€‚è¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£ã€‚"
            showingSettingsAlert = true
            showingPermissionAlert = true
        }
    }
    
    // æ·»åŠ ä¸€ä¸ªæ–¹æ³•æ¥é‡ç½®æœåŠ¡çŠ¶æ€
    private func resetService() {
        print("ğŸ“± VoiceCaptureViewé‡ç½®OpenAIService")
        
        // å®Œå…¨é‡ç½®OpenAIæœåŠ¡
        OpenAIService.shared.reset()
        
        // é‡æ–°è®¢é˜…OpenAIå“åº”
        OpenAIService.shared.onNewResponse = { response in
            self.apiResponseText = response
        }
    }
    
    // æ·»åŠ ä¸€ä¸ªæ–¹æ³•æ¥æ¸…ç†è§†å›¾èµ„æº
    private func cleanupView() {
        // åœæ­¢è¯­éŸ³å½•åˆ¶ï¼ˆå¦‚æœæ­£åœ¨è¿›è¡Œï¼‰
        if voiceCaptureManager.isRecording {
            voiceCaptureManager.stopRecording()
        }
        
        // åœæ­¢è‡ªåŠ¨å‘é€
        OpenAIService.shared.stopAutoSend()
        
        // å–æ¶ˆè®¢é˜…OpenAIå“åº”
        OpenAIService.shared.onNewResponse = nil
        
        // å–æ¶ˆå®šæ—¶å™¨
        stateResetter?.cancel()
        
        // ç§»é™¤é€šçŸ¥è§‚å¯Ÿè€…
        NotificationCenter.default.removeObserver(self, name: .didFinishPlayingTTS, object: nil)
    }
}

// Preview provider
struct VoiceCaptureView_Previews: PreviewProvider {
    static var previews: some View {
        VoiceCaptureView()
    }
}

// ç”¨äºç®¡ç†å…¨å±€è®¡æ—¶å™¨ï¼Œé¿å…å†…å­˜æ³„æ¼
class TimerManager {
    static let shared = TimerManager()
    
    var voiceBlinkTimer: Timer?
    
    private init() {}
    
    deinit {
        voiceBlinkTimer?.invalidate()
    }
} 